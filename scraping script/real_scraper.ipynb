{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b3968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin URL harvesting.\n",
      "Harvesting complete. 1290 URLs to scrape.\n",
      "Exception when handling https://datingnmore.com/site/user/SouthernBorn\n",
      "'NoneType' object has no attribute 'findAll'\n",
      "Exception when handling https://datingnmore.com/site/user/kami05\n",
      "'NoneType' object has no attribute 'findAll'\n",
      "Exception when handling https://datingnmore.com/site/user/Luzzbel\n",
      "'NoneType' object has no attribute 'findAll'\n",
      "Exception when handling https://datingnmore.com/site/user/FredAlvMac\n",
      "'NoneType' object has no attribute 'findAll'\n",
      "Scraping complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "PROFILES='real'\n",
    "\n",
    "iurlrx = re.compile('.* background-image: url\\(([^\\)]+)\\)')\n",
    "\n",
    "remap = {'I am' : 'gender',\n",
    "         'Age' : 'age',\n",
    "         'City' : 'location',\n",
    "         'Marital status' : 'status',\n",
    "         'Username' : 'username',\n",
    "         'Ethnicity' : 'ethnicity',\n",
    "         'Occupation' : 'occupation',\n",
    "         'About me' : 'description',\n",
    "         'My match\\'s age' : 'match_age',\n",
    "         'Children' : 'children',\n",
    "         'Sexual Orientation' : 'orientation',\n",
    "         'Religion' : 'religion',\n",
    "         'Do you smoke' : 'smoking',\n",
    "         'Do you drink' : 'drinking',\n",
    "         'Here for' : 'intent'}\n",
    "\n",
    "def save_image(url):\n",
    "    \"\"\" Take a URL, generate a unique filename, save \n",
    "        the image to said file and return the filename.\"\"\"\n",
    "    ext = url.split('.')[-1]\n",
    "    filename = IMAGEDIR+os.sep+hashlib.md5(url.encode('utf-8')).hexdigest()+'.'+ext\n",
    "    if os.path.exists(filename):\n",
    "        return filename\n",
    "    try:\n",
    "        content = urlopen(url).read()\n",
    "        f = open(filename,'wb') \n",
    "        f.write(content)\n",
    "        f.close()\n",
    "    except e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return filename \n",
    "\n",
    "\n",
    "def scrape_profile(inhandle, outfile):\n",
    "  \"\"\"Scrape an input scamdiggers page for the profile content\n",
    "  of the scammer. \"\"\"\n",
    "  #Read file\n",
    "  html = inhandle.read()\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "  pfnode = soup.find('div', {'class':'profile-BASE_CMP_UserViewWidget'})\n",
    "  avnode = soup.find(id='avatar_console_image')\n",
    "\n",
    "  #Pull the provided profile data out.\n",
    "  rows = pfnode.findAll('tr')\n",
    "  labels = {}\n",
    "  for row in rows:\n",
    "    lab = row.find('td',{'class':'ow_label'})\n",
    "    val = row.find('td',{'class':'ow_value'})\n",
    "    if lab:\n",
    "      labels[lab.get_text()] = val.get_text().strip()\n",
    "\n",
    "  profile = {}\n",
    "\n",
    "  #Populate our own profile structure.\n",
    "  for lab in remap:\n",
    "    if lab in labels:\n",
    "      profile[remap[lab]] = labels[lab]\n",
    "    else:\n",
    "      profile[remap[lab]] = \"-\"\n",
    "  \n",
    "  #Tweak for consistency.\n",
    "  profile['gender'] = profile['gender'].lower()\n",
    "  \n",
    "  #Extract avatar image\n",
    "#   img = iurlrx.match(avnode.attrs['style']).group(1)\n",
    "#   profile['images'] = [save_image(img)]\n",
    "\n",
    "  #Save output\n",
    "  json.dump(profile, open(outfile,'w'))\n",
    "\n",
    "\n",
    "\n",
    "def enumerate_profiles(inhandle):\n",
    "  \"\"\" Extract all the profile page links from\n",
    "  this index page. \"\"\"\n",
    "  html = inhandle.read()\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "  \n",
    "  urls = [ node.find('a')['href'] for node in soup.findAll('div',  {'class':'ow_user_list_data'})]\n",
    "  return urls\n",
    "\n",
    "\n",
    "def scrape():\n",
    "  \"\"\" Harvest profiles from every third page from the site. \"\"\"\n",
    "  urls = []\n",
    "  urlstr=\"http://datingnmore.com/site/users/latest?page={}\" \n",
    "\n",
    "  print(\"Begin URL harvesting.\")\n",
    "\n",
    "  #For every third page (sample size calculated to finish overnight). \n",
    "  for i in range(658,701):\n",
    "    url = urlstr.format(i)\n",
    "    jitter = random.choice([0,1])\n",
    "    try:\n",
    "      urlhandle = urlopen(url)\n",
    "      urls += enumerate_profiles(urlhandle)\n",
    "      time.sleep(1+jitter)\n",
    "    except Exception as e:\n",
    "      print(\"Exception when handling {}\".format(url))\n",
    "      print(e)\n",
    "      break\n",
    "\n",
    "  print(\"Harvesting complete. {} URLs to scrape.\".format(len(urls)))\n",
    "  url_list = pd.DataFrame(urls)\n",
    "  url_list.to_csv(\"urls.csv\",index=False)\n",
    "\n",
    "  for url in urls:\n",
    "    uid = url[34:]\n",
    "    outfile=PROFILES+uid+'.json'\n",
    "    jitter = random.choice([0,1])\n",
    "    try:\n",
    "      urlhandle = urlopen(url)\n",
    "      scrape_profile(urlhandle, outfile)\n",
    "      time.sleep(1+jitter)\n",
    "    except Exception as e:\n",
    "      print(\"Exception when handling {}\".format(url))\n",
    "      print(e)\n",
    " \n",
    "  print(\"Scraping complete.\")\n",
    " \n",
    "\n",
    "\n",
    "scrape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c69dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5332c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2956e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08483a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
