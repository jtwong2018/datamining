{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d8741c",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e56ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "491f0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5e5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv(\"real_profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939e0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scam_df = pd.read_csv(\"scam_profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfc5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([real_df,scam_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b971a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f9e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>filtered sentence</th>\n",
       "      <th>Language</th>\n",
       "      <th>y</th>\n",
       "      <th>translated_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123canwe</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>I full fire friskier hell</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123WILFREDO</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ESTUDIANTE</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>ME GUSTA CONOCER CHICAS BONDADOSAS CARIÑOSAS Y MUY FUERTES EN LA MORAL</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1907</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Construction</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>laid back earth good sense humor</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52Jim52</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>Retired owner aerospace consuloting firm</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Social worker</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>Hello aaron Vermont I vermont 2 years Im really fun person I like camping bone fire etc</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>Social worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abdelghani</td>\n",
       "      <td>71.0</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>problem free flexibleseek love happiness</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "      <td>retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abdul99</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>separated</td>\n",
       "      <td>male</td>\n",
       "      <td>Easy going Highly educated Life beautiful Travels</td>\n",
       "      <td>ro</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abdulrahmanwaly</td>\n",
       "      <td>33.0</td>\n",
       "      <td>journalist</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>name Abdulrahman person ethics religion work field journalism live Cairo</td>\n",
       "      <td>fr</td>\n",
       "      <td>0</td>\n",
       "      <td>journalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abou</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Designer</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>I serious honest trustworthy like share love fan culture new different person</td>\n",
       "      <td>da</td>\n",
       "      <td>0</td>\n",
       "      <td>Designer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accydave</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>My name David Im 71 years old divorced retired 3 grownup children son 2 daughters</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Retired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   age     occupation     status gender  \\\n",
       "0         123canwe  66.0        Retired     single   male   \n",
       "1      123WILFREDO  28.0     ESTUDIANTE     single   male   \n",
       "2             1907  48.0   Construction     single   male   \n",
       "3          52Jim52  70.0        Retired   divorced   male   \n",
       "4          Aaron90  28.0  Social worker     single   male   \n",
       "5       abdelghani  71.0        retired   divorced   male   \n",
       "6          Abdul99  54.0      Executive  separated   male   \n",
       "7  abdulrahmanwaly  33.0     journalist     single   male   \n",
       "8             Abou  33.0       Designer     single   male   \n",
       "9         Accydave  73.0        Retired   divorced   male   \n",
       "\n",
       "                                                                         filtered sentence  \\\n",
       "0                                                                I full fire friskier hell   \n",
       "1                   ME GUSTA CONOCER CHICAS BONDADOSAS CARIÑOSAS Y MUY FUERTES EN LA MORAL   \n",
       "2                                                         laid back earth good sense humor   \n",
       "3                                                 Retired owner aerospace consuloting firm   \n",
       "4  Hello aaron Vermont I vermont 2 years Im really fun person I like camping bone fire etc   \n",
       "5                                                 problem free flexibleseek love happiness   \n",
       "6                                        Easy going Highly educated Life beautiful Travels   \n",
       "7                 name Abdulrahman person ethics religion work field journalism live Cairo   \n",
       "8            I serious honest trustworthy like share love fan culture new different person   \n",
       "9        My name David Im 71 years old divorced retired 3 grownup children son 2 daughters   \n",
       "\n",
       "  Language  y translated_occupation  \n",
       "0       tr  0               Retired  \n",
       "1       es  0               STUDENT  \n",
       "2       en  0          Construction  \n",
       "3       da  0               Retired  \n",
       "4       en  0         Social worker  \n",
       "5       da  0               retired  \n",
       "6       ro  0             Executive  \n",
       "7       fr  0            journalist  \n",
       "8       da  0              Designer  \n",
       "9       tr  0               Retired  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60a44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = combined_df['filtered sentence']\n",
    "\n",
    "# target\n",
    "y = combined_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e8d2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 424)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fd668",
   "metadata": {},
   "source": [
    "# output for slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc87bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "#tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "#tfidf_vect.fit(X)\n",
    "#xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "#xvalid_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc6a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XX = combined_df['filtered sentence'].iloc[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6faae536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "#tfidf_vect.fit(XX)\n",
    "#xtrain_tfidf =  tfidf_vect.transform(XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c22aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tfidf_vect.get_feature_names())  \n",
    "#print('\\n')\n",
    "#print(xtrain_tfidf.shape)\n",
    "#print('\\n')\n",
    "#print(xtrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e81d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xtrain_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb76fd",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier\n",
    "- Taken from: https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32404f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffbc905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#WITHOUT OVERSAMPLING/UNDER SAMPLING\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f24ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2365ef",
   "metadata": {},
   "source": [
    "### Evaluating the NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad95ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n",
      "Accuracy: 0.9188712522045855\n",
      "Precision: 0.8150782361308677\n",
      "recall: 0.9862306368330465\n",
      "f1_score: 0.8925233644859812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"original dataset\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e62f06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "text_clf = MultinomialNB()\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = text_clf.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bf398de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling\n",
      "Accuracy: 0.9200470311581422\n",
      "Precision: 0.8156028368794326\n",
      "recall: 0.9896729776247849\n",
      "f1_score: 0.8942457231726284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b731911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = MultinomialNB()\n",
    "text_clf = text_clf.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989f2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling\n",
      "Accuracy: 0.9200470311581422\n",
      "Precision: 0.8156028368794326\n",
      "recall: 0.9896729776247849\n",
      "f1_score: 0.8942457231726284\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59951a7a",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "746f0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, random_state=42)),\n",
    "])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcfa67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153e9bf",
   "metadata": {},
   "source": [
    "### Evaluating the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "195cc705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9227166276346604\n",
      "Precision: 0.8228187919463087\n",
      "recall: 1.0\n",
      "f1_score: 0.9027982326951398\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bb285de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36b422d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling\n",
      "Accuracy: 0.921222810111699\n",
      "Precision: 0.8125874125874126\n",
      "recall: 1.0\n",
      "f1_score: 0.8966049382716049\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cb4892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5fade99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling\n",
      "Accuracy: 0.921222810111699\n",
      "Precision: 0.8125874125874126\n",
      "recall: 1.0\n",
      "f1_score: 0.8966049382716049\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d627b2f",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bc913a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train model\n",
    "clf_lg = LogisticRegression()  \n",
    "clf_lg = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf',LogisticRegression()),\n",
    "])\n",
    "clf_lg = clf_lg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ad1d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_predictions = clf_lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43353cb1",
   "metadata": {},
   "source": [
    "### Evaluating logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "566c559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.932392710170488\n",
      "Precision: 0.8498498498498499\n",
      "recall: 0.9741824440619621\n",
      "f1_score: 0.9077786688051322\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dc4da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_ros, y_train_ros)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eb1fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling\n",
      "Accuracy: 0.9288653733098178\n",
      "Precision: 0.8304597701149425\n",
      "recall: 0.9948364888123924\n",
      "f1_score: 0.9052466718872357\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb27e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_rus, y_train_rus)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f000370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling\n",
      "Accuracy: 0.9218106995884774\n",
      "Precision: 0.8146067415730337\n",
      "recall: 0.9982788296041308\n",
      "f1_score: 0.897138437741686\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7b463",
   "metadata": {},
   "source": [
    "# Reading real profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f43d280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1bbd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "json_dir = 'data/realprofile'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "realdf = pd.concat(dfs)\n",
    "\n",
    "#adding a new column based on username column - to match with xxx.jpg when combining image captions\n",
    "realdf[\"images\"] = realdf[\"username\"] + \".jpg\"\n",
    "\n",
    "#label\n",
    "realdf[\"y\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a0f52",
   "metadata": {},
   "source": [
    "# Reading scam profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5e9473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 'data/scamprofile'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "scamdf = pd.concat(dfs)\n",
    "\n",
    "#modifying the column \"images\" to join on filename - images = [xxx.jpg], change to xxx.jpg\n",
    "scamdf[\"images\"] = scamdf[\"images\"].apply(lambda x: ''.join(x))\n",
    "\n",
    "#label\n",
    "scamdf[\"y\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0155d8",
   "metadata": {},
   "source": [
    "# Reading image caption json (real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "974a1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 'final caption model/real_labels'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "fn_list = []\n",
    "caption_list = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "        filename = list(data.keys())\n",
    "        caption = list(data.values())\n",
    "    fn_list.extend(filename)\n",
    "    caption_list.extend(caption)\n",
    "\n",
    "image_real_df = pd.DataFrame(data = {\"filename\":fn_list,\"caption\":caption_list})\n",
    "\n",
    "#drop duplicates \n",
    "image_real_df = image_real_df.drop_duplicates(subset = \"filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59679bad",
   "metadata": {},
   "source": [
    "# Reading image caption json (scam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78b27219",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 'final caption model/scam_labels'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "fn_list = []\n",
    "caption_list = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "        filename = list(data.keys())\n",
    "        caption = list(data.values())\n",
    "    fn_list.extend(filename)\n",
    "    caption_list.extend(caption)\n",
    "\n",
    "image_scam_df = pd.DataFrame(data = {\"filename\":fn_list,\"caption\":caption_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ca6252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##concat scam and real profiles\n",
    "scam_and_real = pd.concat([scamdf[[\"username\",\"images\",\"y\"]], realdf[[\"username\",\"images\",\"y\"]]], ignore_index=True)\n",
    "#scam_and_real.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc4f02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine image captions + filename (real and scam) into one df\n",
    "scam_image_and_real_image = pd.concat([image_real_df,image_scam_df],ignore_index = True)\n",
    "scam_image_and_real_image.rename(columns = {\"filename\":\"images\"},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bbe75aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left join scam image and real image captions to scam_and_real\n",
    "final_df = scam_and_real.merge(scam_image_and_real_image,how = 'left', on = 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7901db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine finaldf with combined df\n",
    "final_df3 = combined_df.merge(final_df[[\"username\",\"caption\"]],how = \"left\",on = \"username\")\n",
    "final_df3.dropna(subset = [\"caption\",\"username\"],inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee79fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4607 entries, 0 to 8504\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   username               4607 non-null   object \n",
      " 1   age                    4606 non-null   float64\n",
      " 2   occupation             4604 non-null   object \n",
      " 3   status                 4607 non-null   object \n",
      " 4   gender                 4607 non-null   object \n",
      " 5   filtered sentence      4607 non-null   object \n",
      " 6   Language               4607 non-null   object \n",
      " 7   y                      4607 non-null   int64  \n",
      " 8   translated_occupation  3192 non-null   object \n",
      " 9   caption                4607 non-null   object \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 395.9+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f20e7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use final df3 - create model with both description + caption \n",
    "# features\n",
    "X = final_df3['caption']\n",
    "\n",
    "# target\n",
    "y = final_df3['y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c859e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85096554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef24261",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier for image captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "180dbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "text_clf = MultinomialNB()\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = text_clf.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9f2b25bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling\n",
      "Accuracy: 0.702819956616052\n",
      "Precision: 0.4868421052631579\n",
      "recall: 0.8473282442748091\n",
      "f1_score: 0.6183844011142061\n"
     ]
    }
   ],
   "source": [
    "#evaluating the naive bayes classifier - oversampling\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7429e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "text_clf = MultinomialNB()\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = text_clf.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a62b711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling\n",
      "Accuracy: 0.7017353579175705\n",
      "Precision: 0.485838779956427\n",
      "recall: 0.851145038167939\n",
      "f1_score: 0.6185852981969486\n"
     ]
    }
   ],
   "source": [
    "#evaluating the naive bayes classifier - undersampling\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa83ca",
   "metadata": {},
   "source": [
    "# svm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d4043d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#random oversampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a7d6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling\n",
      "Accuracy: 0.7114967462039046\n",
      "Precision: 0.4957983193277311\n",
      "recall: 0.9007633587786259\n",
      "f1_score: 0.6395663956639566\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1a7b59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6b1b03a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling\n",
      "Accuracy: 0.7158351409978309\n",
      "Precision: 0.5\n",
      "recall: 0.8931297709923665\n",
      "f1_score: 0.6410958904109589\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba9f8f",
   "metadata": {},
   "source": [
    "# logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "710574a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#random oversampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_ros, y_train_ros)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f347c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling\n",
      "Accuracy: 0.7190889370932755\n",
      "Precision: 0.5033407572383074\n",
      "recall: 0.8625954198473282\n",
      "f1_score: 0.6357243319268637\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0e43d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_rus, y_train_rus)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "22782f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling\n",
      "Accuracy: 0.7277657266811279\n",
      "Precision: 0.512249443207127\n",
      "recall: 0.8778625954198473\n",
      "f1_score: 0.6469760900140648\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080aef66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8901fe019d600225f890108c4f0b7852487890258363523329abcb6ca46999d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
