{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d8741c",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e56ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b8aa140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nathangilbert1301.jpg</td>\n",
       "      <td>man in black shirt is standing in front of wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>keneth1.jpg</td>\n",
       "      <td>man in black shirt is standing in front of she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jhjh281.jpg</td>\n",
       "      <td>man in black shirt is standing in front of wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OlegWilliams1.jpg</td>\n",
       "      <td>man in black shirt is standing in front of crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brucep1.jpg</td>\n",
       "      <td>man in black shirt is sitting on bench with he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                            caption\n",
       "0  nathangilbert1301.jpg  man in black shirt is standing in front of wom...\n",
       "1            keneth1.jpg  man in black shirt is standing in front of she...\n",
       "2            Jhjh281.jpg  man in black shirt is standing in front of wom...\n",
       "3      OlegWilliams1.jpg   man in black shirt is standing in front of crowd\n",
       "4            brucep1.jpg  man in black shirt is sitting on bench with he..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json \n",
    "import json\n",
    "\n",
    "# json file paths\n",
    "f = open(r\"final caption model\\christine_scam\\scam_0_500.json\")\n",
    "\n",
    "data = json.load(f)\n",
    "\n",
    "filename = list(data.keys())\n",
    "caption = list(data.values())\n",
    "\n",
    "df = pd.DataFrame(data={'filename':filename, 'caption':caption})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491f0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "     -------------------------------------- 199.3/199.3 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages (from imbalanced-learn) (1.8.1)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading scikit_learn-1.1.3-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "     ---------------------------------------- 7.6/7.6 MB 14.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\christine\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed imbalanced-learn-0.9.1 scikit-learn-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pingouin 0.5.2 requires scikit-learn<1.1.0, but you have scikit-learn 1.1.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\christine\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5e5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"combined_profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b971a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38f9e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>filtered sentence</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123canwe</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>I full fire friskier hell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123WILFREDO</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ESTUDIANTE</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>ME GUSTA CONOCER CHICAS BONDADOSAS CARIÃ‘OSAS Y MUY FUERTES EN LA MORAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1907</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Construction</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>laid back earth good sense humor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52Jim52</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>Retired owner aerospace consuloting firm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Social worker</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>Hello aaron Vermont I vermont 2 years Im really fun person I like camping bone fire etc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abdelghani</td>\n",
       "      <td>71.0</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>problem free flexibleseek love happiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abdul99</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>separated</td>\n",
       "      <td>male</td>\n",
       "      <td>Easy going Highly educated Life beautiful Travels</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abdulrahmanwaly</td>\n",
       "      <td>33.0</td>\n",
       "      <td>journalist</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>name Abdulrahman person ethics religion work field journalism live Cairo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abou</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Designer</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>I serious honest trustworthy like share love fan culture new different person</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accydave</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>My name David Im 71 years old divorced retired 3 grownup children son 2 daughters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   age     occupation     status gender  \\\n",
       "0         123canwe  66.0        Retired     single   male   \n",
       "1      123WILFREDO  28.0     ESTUDIANTE     single   male   \n",
       "2             1907  48.0   Construction     single   male   \n",
       "3          52Jim52  70.0        Retired   divorced   male   \n",
       "4          Aaron90  28.0  Social worker     single   male   \n",
       "5       abdelghani  71.0        retired   divorced   male   \n",
       "6          Abdul99  54.0      Executive  separated   male   \n",
       "7  abdulrahmanwaly  33.0     journalist     single   male   \n",
       "8             Abou  33.0       Designer     single   male   \n",
       "9         Accydave  73.0        Retired   divorced   male   \n",
       "\n",
       "                                                                         filtered sentence  \\\n",
       "0                                                                I full fire friskier hell   \n",
       "1                   ME GUSTA CONOCER CHICAS BONDADOSAS CARIÃ‘OSAS Y MUY FUERTES EN LA MORAL   \n",
       "2                                                         laid back earth good sense humor   \n",
       "3                                                 Retired owner aerospace consuloting firm   \n",
       "4  Hello aaron Vermont I vermont 2 years Im really fun person I like camping bone fire etc   \n",
       "5                                                 problem free flexibleseek love happiness   \n",
       "6                                        Easy going Highly educated Life beautiful Travels   \n",
       "7                 name Abdulrahman person ethics religion work field journalism live Cairo   \n",
       "8            I serious honest trustworthy like share love fan culture new different person   \n",
       "9        My name David Im 71 years old divorced retired 3 grownup children son 2 daughters   \n",
       "\n",
       "   y  \n",
       "0  0  \n",
       "1  0  \n",
       "2  0  \n",
       "3  0  \n",
       "4  0  \n",
       "5  0  \n",
       "6  0  \n",
       "7  0  \n",
       "8  0  \n",
       "9  0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b60a44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = combined_df['filtered sentence']\n",
    "\n",
    "# target\n",
    "y = combined_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e8d2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 424)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fd668",
   "metadata": {},
   "source": [
    "# output for slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc87bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bc6a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = combined_df['filtered sentence'].iloc[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6faae536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(XX)\n",
    "xtrain_tfidf =  tfidf_vect.transform(XX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42c22aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', 'aaron', 'aerospace', 'back', 'bone', 'camping', 'consuloting', 'earth', 'etc', 'fire', 'firm', 'fun', 'good', 'hello', 'humor', 'i', 'im', 'laid', 'like', 'owner', 'person', 'really', 'retired', 'sense', 'vermont', 'years']\n",
      "\n",
      "\n",
      "(3, 26)\n",
      "\n",
      "\n",
      "  (0, 23)\t0.4082482904638631\n",
      "  (0, 17)\t0.4082482904638631\n",
      "  (0, 14)\t0.4082482904638631\n",
      "  (0, 12)\t0.4082482904638631\n",
      "  (0, 7)\t0.4082482904638631\n",
      "  (0, 3)\t0.4082482904638631\n",
      "  (1, 22)\t0.4472135954999579\n",
      "  (1, 19)\t0.4472135954999579\n",
      "  (1, 10)\t0.4472135954999579\n",
      "  (1, 6)\t0.4472135954999579\n",
      "  (1, 2)\t0.4472135954999579\n",
      "  (2, 25)\t0.21821789023599233\n",
      "  (2, 24)\t0.43643578047198467\n",
      "  (2, 21)\t0.21821789023599233\n",
      "  (2, 20)\t0.21821789023599233\n",
      "  (2, 18)\t0.21821789023599233\n",
      "  (2, 16)\t0.21821789023599233\n",
      "  (2, 15)\t0.43643578047198467\n",
      "  (2, 13)\t0.21821789023599233\n",
      "  (2, 11)\t0.21821789023599233\n",
      "  (2, 9)\t0.21821789023599233\n",
      "  (2, 8)\t0.21821789023599233\n",
      "  (2, 5)\t0.21821789023599233\n",
      "  (2, 4)\t0.21821789023599233\n",
      "  (2, 1)\t0.21821789023599233\n",
      "  (2, 0)\t0.21821789023599233\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vect.get_feature_names())  \n",
    "print('\\n')\n",
    "print(xtrain_tfidf.shape)\n",
    "print('\\n')\n",
    "print(xtrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35e81d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.40824829 0.         0.\n",
      "  0.         0.40824829 0.         0.         0.         0.\n",
      "  0.40824829 0.         0.40824829 0.         0.         0.40824829\n",
      "  0.         0.         0.         0.         0.         0.40824829\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.4472136  0.         0.         0.\n",
      "  0.4472136  0.         0.         0.         0.4472136  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.4472136  0.         0.         0.4472136  0.\n",
      "  0.         0.        ]\n",
      " [0.21821789 0.21821789 0.         0.         0.21821789 0.21821789\n",
      "  0.         0.         0.21821789 0.21821789 0.         0.21821789\n",
      "  0.         0.21821789 0.         0.43643578 0.21821789 0.\n",
      "  0.21821789 0.         0.21821789 0.21821789 0.         0.\n",
      "  0.43643578 0.21821789]]\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb76fd",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier\n",
    "- Taken from: https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32404f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbc905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#WITHOUT OVERSAMPLING/UNDER SAMPLING\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f24ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2365ef",
   "metadata": {},
   "source": [
    "### Evaluating the NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad95ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n",
      "Accuracy: 0.9262295081967213\n",
      "Precision: 0.8294993234100135\n",
      "recall: 1.0\n",
      "f1_score: 0.9068047337278106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"original dataset\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e62f06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "text_clf = MultinomialNB()\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = text_clf.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bf398de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling\n",
      "Accuracy: 0.9268149882903981\n",
      "Precision: 0.8306233062330624\n",
      "recall: 1.0\n",
      "f1_score: 0.9074759437453738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b731911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = MultinomialNB()\n",
    "text_clf = text_clf.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "989f2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling\n",
      "Accuracy: 0.9256440281030445\n",
      "Precision: 0.8283783783783784\n",
      "recall: 1.0\n",
      "f1_score: 0.9061345158906134\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59951a7a",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "746f0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, random_state=42)),\n",
    "])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcfa67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153e9bf",
   "metadata": {},
   "source": [
    "### Evaluating the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "195cc705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9227166276346604\n",
      "Precision: 0.8228187919463087\n",
      "recall: 1.0\n",
      "f1_score: 0.9027982326951398\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bb285de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36b422d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling\n",
      "Accuracy: 0.9221311475409836\n",
      "Precision: 0.82171581769437\n",
      "recall: 1.0\n",
      "f1_score: 0.9021339220014717\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6cb4892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5fade99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling\n",
      "Accuracy: 0.9221311475409836\n",
      "Precision: 0.82171581769437\n",
      "recall: 1.0\n",
      "f1_score: 0.9021339220014717\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d627b2f",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3bc913a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train model\n",
    "clf_lg = LogisticRegression()  \n",
    "clf_lg = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf',LogisticRegression()),\n",
    "])\n",
    "clf_lg = clf_lg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ad1d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_predictions = clf_lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43353cb1",
   "metadata": {},
   "source": [
    "### Evaluating logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "566c559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9106641721234799\n",
      "Precision: 0.7995283018867925\n",
      "recall: 0.9699570815450643\n",
      "f1_score: 0.8765352294764058\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1dc4da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_ros, y_train_ros)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4eb1fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling\n",
      "Accuracy: 0.9320843091334895\n",
      "Precision: 0.8446601941747572\n",
      "recall: 0.9934747145187602\n",
      "f1_score: 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb27e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_rus, y_train_rus)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f000370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling\n",
      "Accuracy: 0.9250585480093677\n",
      "Precision: 0.8272604588394062\n",
      "recall: 1.0\n",
      "f1_score: 0.9054652880354505\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7b463",
   "metadata": {},
   "source": [
    "# Reading real profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bbd2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "json_dir = 'data/realprofile'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "realdf = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc6a17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>location</th>\n",
       "      <th>status</th>\n",
       "      <th>username</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>occupation</th>\n",
       "      <th>description</th>\n",
       "      <th>match_age</th>\n",
       "      <th>children</th>\n",
       "      <th>orientation</th>\n",
       "      <th>religion</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>intent</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>62 y.o.</td>\n",
       "      <td>Nashville, TN, USA</td>\n",
       "      <td>divorced</td>\n",
       "      <td>Suzy60</td>\n",
       "      <td>white</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>-</td>\n",
       "      <td>from 45 to 65</td>\n",
       "      <td>1-2 living with me</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Spiritual</td>\n",
       "      <td>social smoker</td>\n",
       "      <td>occasional drinker</td>\n",
       "      <td>Friendship</td>\n",
       "      <td>realSuzy60.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>56 y.o.</td>\n",
       "      <td>Pedregal del Cortez, 23018 La Paz, B.C.S., MÃ©xico</td>\n",
       "      <td>divorced</td>\n",
       "      <td>cone66</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>construcciÃ³n</td>\n",
       "      <td>-</td>\n",
       "      <td>from 38 to 49</td>\n",
       "      <td>1-2 living elsewhere</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Christian</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>social drinker</td>\n",
       "      <td>Fun, Friendship, Romance</td>\n",
       "      <td>realcone66.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>53 y.o.</td>\n",
       "      <td>Stockholm, Sweden</td>\n",
       "      <td>separated</td>\n",
       "      <td>DrOo</td>\n",
       "      <td>white</td>\n",
       "      <td>teacher</td>\n",
       "      <td>-</td>\n",
       "      <td>from 30 to 48</td>\n",
       "      <td>1-2 living with me</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Christian</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>social drinker</td>\n",
       "      <td>Romance, Serious Relationship, Marriage</td>\n",
       "      <td>realDrOo.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>40 y.o.</td>\n",
       "      <td>BogotÃ¡, Colombia</td>\n",
       "      <td>single</td>\n",
       "      <td>Leyjo</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>Fisioterapeuta</td>\n",
       "      <td>-</td>\n",
       "      <td>from 31 to 45</td>\n",
       "      <td>no children</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Christian</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>social drinker</td>\n",
       "      <td>Serious Relationship</td>\n",
       "      <td>realLeyjo.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>31 y.o.</td>\n",
       "      <td>Manizales, Caldas, Colombia</td>\n",
       "      <td>single</td>\n",
       "      <td>Paoramirez08</td>\n",
       "      <td>white</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>from 23 to 40</td>\n",
       "      <td>no children</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Other</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>never</td>\n",
       "      <td>Romance, Serious Relationship, Marriage</td>\n",
       "      <td>realPaoramirez08.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender      age                                           location  \\\n",
       "0  female  62 y.o.                                 Nashville, TN, USA   \n",
       "0    male  56 y.o.  Pedregal del Cortez, 23018 La Paz, B.C.S., MÃ©xico   \n",
       "0    male  53 y.o.                                  Stockholm, Sweden   \n",
       "0  female  40 y.o.                                   BogotÃ¡, Colombia   \n",
       "0  female  31 y.o.                        Manizales, Caldas, Colombia   \n",
       "\n",
       "      status      username ethnicity      occupation description  \\\n",
       "0   divorced        Suzy60     white         Teacher           -   \n",
       "0   divorced        cone66  hispanic    construcciÃ³n           -   \n",
       "0  separated          DrOo     white         teacher           -   \n",
       "0     single         Leyjo  hispanic  Fisioterapeuta           -   \n",
       "0     single  Paoramirez08     white               -           -   \n",
       "\n",
       "       match_age              children orientation   religion        smoking  \\\n",
       "0  from 45 to 65    1-2 living with me    Straight  Spiritual  social smoker   \n",
       "0  from 38 to 49  1-2 living elsewhere    Straight  Christian     non-smoker   \n",
       "0  from 30 to 48    1-2 living with me    Straight  Christian     non-smoker   \n",
       "0  from 31 to 45           no children    Straight  Christian     non-smoker   \n",
       "0  from 23 to 40           no children    Straight      Other     non-smoker   \n",
       "\n",
       "             drinking                                   intent  \\\n",
       "0  occasional drinker                               Friendship   \n",
       "0      social drinker                 Fun, Friendship, Romance   \n",
       "0      social drinker  Romance, Serious Relationship, Marriage   \n",
       "0      social drinker                     Serious Relationship   \n",
       "0               never  Romance, Serious Relationship, Marriage   \n",
       "\n",
       "                    site  \n",
       "0        realSuzy60.json  \n",
       "0        realcone66.json  \n",
       "0          realDrOo.json  \n",
       "0         realLeyjo.json  \n",
       "0  realPaoramirez08.json  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a0f52",
   "metadata": {},
   "source": [
    "# Reading scam profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 'data/scamprofile'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "scamdf = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0155d8",
   "metadata": {},
   "source": [
    "# Reading image caption json (real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974a1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 'final caption model/xinyi_real'\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "        json_data['site'] = file.rsplit(\"/\", 1)[-1]\n",
    "    dfs.append(json_data)\n",
    "image_real_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b5c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>123canwe.jpg</th>\n",
       "      <th>123WILFREDO.jpg</th>\n",
       "      <th>52Jim52.jpg</th>\n",
       "      <th>Aaron90.jpg</th>\n",
       "      <th>Abou.jpg</th>\n",
       "      <th>Agatha123.jpg</th>\n",
       "      <th>Ahin.jpg</th>\n",
       "      <th>Airik.jpg</th>\n",
       "      <th>alaaeldin.jpg</th>\n",
       "      <th>Alexmmar.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>zJoseManueL.jpg</th>\n",
       "      <th>Zohe.jpg</th>\n",
       "      <th>zorro.jpg</th>\n",
       "      <th>Zschweitz418.jpg</th>\n",
       "      <th>Zulemaa.jpg</th>\n",
       "      <th>Zulia.jpg</th>\n",
       "      <th>ZullynAzul2.jpg</th>\n",
       "      <th>Zwadiemarie22.jpg</th>\n",
       "      <th>Zxxxx.jpg</th>\n",
       "      <th>_Diana_.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man in red shirt is standing on bench next to ...</td>\n",
       "      <td>man in red shirt is sitting on the edge of river</td>\n",
       "      <td>man in black shirt is standing in front of woo...</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>man in red shirt and black shorts is walking d...</td>\n",
       "      <td>young girl in pink shirt is standing in front ...</td>\n",
       "      <td>man in black shirt is standing in front of store</td>\n",
       "      <td>man in black shirt is smiling at the camera</td>\n",
       "      <td>man in black shirt and black shirt is standing...</td>\n",
       "      <td>man in black shirt is smiling</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man in red shirt is standing on bench next to ...</td>\n",
       "      <td>man in red shirt is sitting on the edge of river</td>\n",
       "      <td>man in black shirt is standing in front of woo...</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>man in red shirt and black shorts is walking d...</td>\n",
       "      <td>young girl in pink shirt is standing in front ...</td>\n",
       "      <td>man in black shirt is standing in front of store</td>\n",
       "      <td>man in black shirt is smiling at the camera</td>\n",
       "      <td>man in black shirt and black shirt is standing...</td>\n",
       "      <td>man in black shirt is smiling</td>\n",
       "      <td>...</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>woman in black shirt and sunglasses is sitting...</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>man in red shirt is standing in front of crowd</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>two women are sitting on bench in front of the...</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "      <td>two girls are sitting on the floor</td>\n",
       "      <td>two girls are playing in the grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        123canwe.jpg  \\\n",
       "0  man in red shirt is standing on bench next to ...   \n",
       "0                                                NaN   \n",
       "0  man in red shirt is standing on bench next to ...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                    123WILFREDO.jpg  \\\n",
       "0  man in red shirt is sitting on the edge of river   \n",
       "0                                               NaN   \n",
       "0  man in red shirt is sitting on the edge of river   \n",
       "0                                               NaN   \n",
       "0                                               NaN   \n",
       "\n",
       "                                         52Jim52.jpg  \\\n",
       "0  man in black shirt is standing in front of woo...   \n",
       "0                                                NaN   \n",
       "0  man in black shirt is standing in front of woo...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                          Aaron90.jpg  \\\n",
       "0  two girls are playing in the grass   \n",
       "0                                 NaN   \n",
       "0  two girls are playing in the grass   \n",
       "0                                 NaN   \n",
       "0                                 NaN   \n",
       "\n",
       "                                            Abou.jpg  \\\n",
       "0  man in red shirt and black shorts is walking d...   \n",
       "0                                                NaN   \n",
       "0  man in red shirt and black shorts is walking d...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                       Agatha123.jpg  \\\n",
       "0  young girl in pink shirt is standing in front ...   \n",
       "0                                                NaN   \n",
       "0  young girl in pink shirt is standing in front ...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                           Ahin.jpg  \\\n",
       "0  man in black shirt is standing in front of store   \n",
       "0                                               NaN   \n",
       "0  man in black shirt is standing in front of store   \n",
       "0                                               NaN   \n",
       "0                                               NaN   \n",
       "\n",
       "                                     Airik.jpg  \\\n",
       "0  man in black shirt is smiling at the camera   \n",
       "0                                          NaN   \n",
       "0  man in black shirt is smiling at the camera   \n",
       "0                                          NaN   \n",
       "0                                          NaN   \n",
       "\n",
       "                                       alaaeldin.jpg  \\\n",
       "0  man in black shirt and black shirt is standing...   \n",
       "0                                                NaN   \n",
       "0  man in black shirt and black shirt is standing...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                    Alexmmar.jpg  ...                     zJoseManueL.jpg  \\\n",
       "0  man in black shirt is smiling  ...                                 NaN   \n",
       "0                            NaN  ...                                 NaN   \n",
       "0  man in black shirt is smiling  ...  two girls are playing in the grass   \n",
       "0                            NaN  ...                                 NaN   \n",
       "0                            NaN  ...                                 NaN   \n",
       "\n",
       "                                            Zohe.jpg  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  woman in black shirt and sunglasses is sitting...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                            zorro.jpg  \\\n",
       "0                                 NaN   \n",
       "0                                 NaN   \n",
       "0  two girls are playing in the grass   \n",
       "0                                 NaN   \n",
       "0                                 NaN   \n",
       "\n",
       "                                 Zschweitz418.jpg  \\\n",
       "0                                             NaN   \n",
       "0                                             NaN   \n",
       "0  man in red shirt is standing in front of crowd   \n",
       "0                                             NaN   \n",
       "0                                             NaN   \n",
       "\n",
       "                          Zulemaa.jpg  \\\n",
       "0                                 NaN   \n",
       "0                                 NaN   \n",
       "0  two girls are playing in the grass   \n",
       "0                                 NaN   \n",
       "0                                 NaN   \n",
       "\n",
       "                                           Zulia.jpg  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  two women are sitting on bench in front of the...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                      ZullynAzul2.jpg                   Zwadiemarie22.jpg  \\\n",
       "0                                 NaN                                 NaN   \n",
       "0                                 NaN                                 NaN   \n",
       "0  two girls are playing in the grass  two girls are playing in the grass   \n",
       "0                                 NaN                                 NaN   \n",
       "0                                 NaN                                 NaN   \n",
       "\n",
       "                            Zxxxx.jpg                         _Diana_.jpg  \n",
       "0                                 NaN                                 NaN  \n",
       "0                                 NaN                                 NaN  \n",
       "0  two girls are sitting on the floor  two girls are playing in the grass  \n",
       "0                                 NaN                                 NaN  \n",
       "0                                 NaN                                 NaN  \n",
       "\n",
       "[5 rows x 3200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_real_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b7568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8901fe019d600225f890108c4f0b7852487890258363523329abcb6ca46999d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
