{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d8741c",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e56ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "491f0804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (2.1.0)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading scikit_learn-1.1.3-cp38-cp38-macosx_10_9_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.0.1)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.1\n",
      "    Uninstalling scikit-learn-0.24.1:\n",
      "      Successfully uninstalled scikit-learn-0.24.1\n",
      "Successfully installed imbalanced-learn-0.9.1 scikit-learn-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling and under sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5e5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"combined_profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b971a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>filtered sentence</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123canwe</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>I full fire friskier hell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123WILFREDO</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ESTUDIANTE</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>ME GUSTA CONOCER CHICAS BONDADOSAS CARIÑOSAS Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1907</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Construction</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>laid back earth good sense humor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52Jim52</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>male</td>\n",
       "      <td>Retired owner aerospace consuloting firm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Social worker</td>\n",
       "      <td>single</td>\n",
       "      <td>male</td>\n",
       "      <td>Hello aaron Vermont I vermont 2 years Im reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username   age     occupation    status gender  \\\n",
       "0     123canwe  66.0        Retired    single   male   \n",
       "1  123WILFREDO  28.0     ESTUDIANTE    single   male   \n",
       "2         1907  48.0   Construction    single   male   \n",
       "3      52Jim52  70.0        Retired  divorced   male   \n",
       "4      Aaron90  28.0  Social worker    single   male   \n",
       "\n",
       "                                   filtered sentence  y  \n",
       "0                          I full fire friskier hell  0  \n",
       "1  ME GUSTA CONOCER CHICAS BONDADOSAS CARIÑOSAS Y...  0  \n",
       "2                   laid back earth good sense humor  0  \n",
       "3           Retired owner aerospace consuloting firm  0  \n",
       "4  Hello aaron Vermont I vermont 2 years Im reall...  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d929bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = combined_df['filtered sentence']\n",
    "\n",
    "# target\n",
    "y = combined_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8d2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 424)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc87bd4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d2a4fd6d711d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# word level tf-idf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidf_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr'\\w{1,}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxtrain_tfidf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxvalid_tfidf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtfidf_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c275a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5efb76fd",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier\n",
    "- Taken from: https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32404f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffbc905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#WITHOUT OVERSAMPLING/UNDER SAMPLING\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    " ])\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f24ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2365ef",
   "metadata": {},
   "source": [
    "### Evaluating the NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad95ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n",
      "Accuracy: 0.8718428437792329\n",
      "Precision: 0.7211238293444329\n",
      "recall: 0.9914163090128756\n",
      "f1_score: 0.8349397590361446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"original dataset\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e62f06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=100000)\n",
    "tfidf_vect.fit(X)\n",
    "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
    "xvalid_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "text_clf = MultinomialNB()\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = text_clf.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bf398de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random oversampling\n",
      "Accuracy: 0.8718428437792329\n",
      "Precision: 0.7197518097207859\n",
      "recall: 0.9957081545064378\n",
      "f1_score: 0.8355342136854741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b731911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf = MultinomialNB()\n",
    "text_clf = text_clf.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "989f2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random undersampling\n",
      "Accuracy: 0.8709073900841908\n",
      "Precision: 0.718717683557394\n",
      "recall: 0.994277539341917\n",
      "f1_score: 0.8343337334933973\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"random undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59951a7a",
   "metadata": {},
   "source": [
    "# SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "746f0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                            alpha=1e-3, random_state=42)),\n",
    "])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcfa67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153e9bf",
   "metadata": {},
   "source": [
    "### Evaluating the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "195cc705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8699719363891487\n",
      "Precision: 0.7158974358974359\n",
      "recall: 0.9985693848354793\n",
      "f1_score: 0.8339307048984469\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bb285de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_ros, y_train_ros)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36b422d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampling\n",
      "Accuracy: 0.8685687558465855\n",
      "Precision: 0.713265306122449\n",
      "recall: 1.0\n",
      "f1_score: 0.8326384752829065\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"oversampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cb4892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "text_clf_svm = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "text_clf_svm = text_clf_svm.fit(X_train_rus, y_train_rus)\n",
    "predictions = text_clf_svm.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5fade99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling\n",
      "Accuracy: 0.8685687558465855\n",
      "Precision: 0.713265306122449\n",
      "recall: 1.0\n",
      "f1_score: 0.8326384752829065\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"undersampling\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d627b2f",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3bc913a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train model\n",
    "clf_lg = LogisticRegression()  \n",
    "clf_lg = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf',LogisticRegression()),\n",
    "])\n",
    "clf_lg = clf_lg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ad1d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_predictions = clf_lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43353cb1",
   "metadata": {},
   "source": [
    "### Evaluating logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "566c559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9106641721234799\n",
      "Precision: 0.7995283018867925\n",
      "recall: 0.9699570815450643\n",
      "f1_score: 0.8765352294764058\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dc4da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random oversampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_ros, y_train_ros= ros.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_ros, y_train_ros)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4eb1fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8947614593077643\n",
      "Precision: 0.7615894039735099\n",
      "recall: 0.9871244635193133\n",
      "f1_score: 0.8598130841121495\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb27e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random undersampling\n",
    "clf_lg = LogisticRegression()  \n",
    "\n",
    "ros = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_rus, y_train_rus= rus.fit_resample(xtrain_tfidf, y_train)\n",
    "clf_lg = clf_lg.fit(X_train_rus, y_train_rus)\n",
    "lg_predictions = clf_lg.predict(xvalid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f000370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8802619270346118\n",
      "Precision: 0.7348886532343585\n",
      "recall: 0.9914163090128756\n",
      "f1_score: 0.8440925700365408\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, lg_predictions)\n",
    "tn = conf_matrix[0][0]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "\n",
    "accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision + recall)\n",
    "\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"recall:\",recall)\n",
    "print(\"f1_score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbd2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
